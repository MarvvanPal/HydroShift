## Project Name

---

HydroShift (Formerly Exploring XR)


## Project Topic

---

### Problem we are trying to solve
After a few years of availability of XR-soft- and hardware, we see different approaches to using this technology. Common are cases in gaming (e.g., VR) and business (e.g., AR). The potential to use this immersive technology in a meaningful way has not yet been exhausted.
People are not aware of some impacts they are doing through consumption decisions. Even if they are searching for these information, they find abstract data which are not easy to imagine (e.g., water consumption or ingredients with unknown supply-chains.)

### Goal we want to achieve
In this mixed reality (MR) prototype project, we try to convert abstract data into concrete information. We refer to abstract data as the hidden consumption of water in manufacturing products. To make this more concrete, we use MR to visualize this amount of water in relation to the size of the product. The goal is to change grocery customers' thinking and behavior while shopping in grocery.


### Usecase
In this future related approach a customer is entering a grocery and stats shopping. While the customer is wearing  mixed reality glasses they can scan and select a product. The glasses are showing the hidden water consumption in a concrete manner. For example, the amount of needed water to produce one kilogram of cocoa can displayed right next to it. Through this they could get more affected. Based on this, they can overthink about their consumption decision. The solution can build a bridge between abstract data and influencing information. 

[See the prototype of the future-oriented project in action in this video.](https://raw.githubusercontent.com/MarvvanPal/HydroShift/main/doc/HydroShift_v1-5_shrinked_LinkedIn.mp4)

## Project Phase and Focus

---
Domain: **Discover** the world of eXtended Reality (XR), **Learning** by applying hardware and software-environments, **Create** meaningful applications

The project is in the state after a first prototype. Research and Design is done in the first iteration. The goal is to pursuit the mentioned approach to use the potential of XR.

Next main steps will be:
- Improving visual effects
- Improving technology like using the ability of spacial awareness from Hololens 2
- Implementing Product selection via image recognition
- Deploying on Hololens 2 and on Meta Quest 2 and maybe Meta Quest Pro (Devices are available through this project)


## Tech-Stack

---

We are using Microsoft Visual Studio 2019, [Unity](https://unity.com/) and [MRTK3](https://docs.microsoft.com/en-us/windows/mixed-reality/mrtk-unity/mrtk3-overview/).
The MRTK3-approach keeps the door open to work crossplatform. With this, we can maybe avoid environmental changes. The downside of this is that we are more or less forced to use **Microsoft Windows**, but maybe we are able to enable our MacOS and Linux-Users through cloud-solutions like [shadow.tech](shadow.tech).
Hardwarewise we are focusing on Microsoft Hololens 2 primarly. Additionally we can expand it to Meta Quest 2 and maybe Meta Quest Pro.
